{"cells":[{"cell_type":"markdown","metadata":{"id":"8FmDM7idYISQ"},"source":["# 단어와 문자의 원-핫 인코딩\n","\n","- 원-핫 인코딩은 토큰을 벡터로 변환하는 가장 일반적이고 기본적인 방법입니다. \n","- 모든 단어에 고유한 정수 인덱스를 부여하고 이 정수 인덱스 i를 크기가 N(어휘 사전의 크기)인 이진 벡터로 변환합니다. \n","- 이 벡터는 i번째 원소만 1이고 나머지는 모두 0입니다.\n","\n","- 물론 원-핫 인코딩은 문자 수준에서도 적용할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"mvWZJwPkYISR"},"source":["단어 수준의 원-핫 인코딩(간단한 예):"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJscvsS6dphw","executionInfo":{"status":"ok","timestamp":1649812111994,"user_tz":-540,"elapsed":20535,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"4eda495b-a1d1-46f2-b1ef-fec15bc2ab0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6gqYLozYISS"},"outputs":[],"source":["import numpy as np\n","\n","# 초기 데이터: 각 원소가 샘플입니다\n","# (이 예에서 하나의 샘플이 하나의 문장입니다. 하지만 문서 전체가 될 수도 있습니다)\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 데이터에 있는 모든 토큰의 인덱스를 구축합니다\n","token_index = {}\n","for sample in samples:\n","    # split() 메서드를 사용해 샘플을 토큰으로 나눕니다.\n","    # 실전에서는 구둣점과 특수 문자도 사용합니다.\n","    for word in sample.split():\n","        if word not in token_index:\n","            # 단어마다 고유한 인덱스를 할당합니다.\n","            token_index[word] = len(token_index) + 1\n","            # 인덱스 0은 사용하지 않습니다.\n","\n","# 샘플을 벡터로 변환합니다.\n","# 각 샘플에서 max_length 까지 단어만 사용합니다.\n","max_length = 10\n","\n","# 결과를 저장할 배열입니다\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        index = token_index.get(word)\n","        results[i, j, index] = 1."]},{"cell_type":"code","source":["results[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGbebVB0eG3S","executionInfo":{"status":"ok","timestamp":1649812222027,"user_tz":-540,"elapsed":2,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"0874d09b-614e-4055-9905-0a72ab5cd35b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"LWWsP14MYIST"},"source":["문자 수준 원-핫 인코딩(간단한 예)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwfKWwwlYIST"},"outputs":[],"source":["import string\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","characters = string.printable  # 출력 가능한 모든 아스키(ASCII) 문자\n","token_index = dict(zip(characters, range(1, len(characters) + 1)))\n","\n","max_length = 50\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","for i, sample in enumerate(samples):\n","    for j, character in enumerate(sample[:max_length]):\n","        index = token_index.get(character)\n","        results[i, j, index] = 1."]},{"cell_type":"code","source":["results[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzLv6dc8fKlH","executionInfo":{"status":"ok","timestamp":1649812487879,"user_tz":-540,"elapsed":366,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"f893a349-7f4a-4099-d093-6d1a78cc5e82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"KshlIN58YISU"},"source":["케라스에는 원본 텍스트 데이터를 단어 또는 문자 수준의 원-핫 인코딩으로 변환해주는 유틸리티가 있습니다. 특수 문자를 제거하거나 빈도가 높은 N개의 단어만을 선택(입력 벡터 공간이 너무 커지지 않도록 하기 위한 일반적인 제한 방법입니다)하는 등 여러 가지 중요한 기능들이 있기 때문에 이 유틸리티를 사용하는 것이 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"cRGuAQ2YYISU"},"source":["케라스를 사용한 단어 수준의 원-핫 인코딩:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kS3F32SIYISU","executionInfo":{"status":"ok","timestamp":1649812493980,"user_tz":-540,"elapsed":2030,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"f15fcb70-c6d2-4830-bd0b-ae8860bd837f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 9 unique tokens.\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 가장 빈도가 높은 1,000개의 단어만 선택하도록 Tokenizer 객체를 만듭니다.\n","tokenizer = Tokenizer(num_words=1000)\n","# 단어 인덱스를 구축합니다.\n","tokenizer.fit_on_texts(samples)\n","\n","# 문자열을 정수 인덱스의 리스트로 변환합니다.\n","sequences = tokenizer.texts_to_sequences(samples)\n","\n","# 직접 원-핫 이진 벡터 표현을 얻을 수 있습니다.\n","# 원-핫 인코딩 외에 다른 벡터화 방법들도 제공합니다!\n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n","\n","# 계산된 단어 인덱스를 구합니다.\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"]},{"cell_type":"code","source":["sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcZOKw5yhA-x","executionInfo":{"status":"ok","timestamp":1649812974140,"user_tz":-540,"elapsed":366,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"d5eb2817-22ea-42c8-af85-c3cbc15fb990"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["one_hot_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eji-WWjchDXw","executionInfo":{"status":"ok","timestamp":1649813015166,"user_tz":-540,"elapsed":5,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"60851ba5-0710-4516-f869-4142e78ecefd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 1., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-W704zeafNwC","executionInfo":{"status":"ok","timestamp":1649812501626,"user_tz":-540,"elapsed":389,"user":{"displayName":"믿을조","userId":"15204951959998370886"}},"outputId":"5be8d34e-9fb8-4c21-95b9-be877af1af41"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ate': 7,\n"," 'cat': 2,\n"," 'dog': 6,\n"," 'homework': 9,\n"," 'mat': 5,\n"," 'my': 8,\n"," 'on': 4,\n"," 'sat': 3,\n"," 'the': 1}"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["[과제] 영어 5개 문장으로 구성된 텍스트를 가져와서 다음을 수행하세요.\n","- 수작업으로 벡터화\n","- Keras를 사용해 벡터화"],"metadata":{"id":"JeXOGvyMiAhJ"}},{"cell_type":"code","source":[""],"metadata":{"id":"vQZsSoxHBOtO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKrRjiN-YISV"},"source":["원-핫 인코딩의 변종 중 하나는 원-핫 해싱 기법입니다. 이 방식은 어휘 사전에 있는 고유한 토큰의 수가 너무 커서 모두 다루기 어려울 때 사용합니다. 각 단어에 명시적으로 인덱스를 할당하고 이 인덱스를 딕셔너리에 저장하는 대신에 단어를 해싱하여 고정된 크기의 벡터로 변환합니다. 일반적으로 간단한 해싱 함수를 사용합니다. 이 방식의 주요 장점은 명시적인 단어 인덱스가 필요 없기 때문에 메모리를 절약하고 온라인 방식으로 데이터를 인코딩할 수 있습니다(전체 데이터를 확인하지 않고 토큰을 생성할 수 있습니다). 한 가지 단점은 해시 충돌입니다. 두 개의 단어가 같은 해시를 만들면 이를 바라보는 머신 러닝 모델은 단어 사이의 차이를 인식하지 못합니다. 해싱 공간의 차원이 해싱될 고유 토큰의 전체 개수보다 훨씬 크면 해시 충돌의 가능성은 감소합니다."]},{"cell_type":"markdown","metadata":{"id":"ZI9TU0DuYISW"},"source":["해싱 기법을 사용한 단어 수준의 원-핫 인코딩(간단한 예):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6YGxC6BYISW"},"outputs":[],"source":["samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 단어를 크기가 1,000인 벡터로 저장합니다.\n","# 1,000개(또는 그이상)의 단어가 있다면 해싱 충돌이 늘어나고 인코딩의 정확도가 감소될 것입니다\n","dimensionality = 1000\n","max_length = 10\n","\n","results = np.zeros((len(samples), max_length, dimensionality))\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        # 단어를 해싱하여 0과 1,000 사이의 랜덤한 정수 인덱스로 변환합니다.\n","        index = abs(hash(word)) % dimensionality\n","        results[i, j, index] = 1."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"DL_one-hot-encoding-of-words-or-characters.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}